{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample several datas: \n",
      "X_train:  [\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\", \"From: guykuo@carson.u.washington.edu (Guy Kuo)\\nSubject: SI Clock Poll - Final Call\\nSummary: Final call for SI clock reports\\nKeywords: SI,acceleration,clock,upgrade\\nArticle-I.D.: shelley.1qvfo9INNc3s\\nOrganization: University of Washington\\nLines: 11\\nNNTP-Posting-Host: carson.u.washington.edu\\n\\nA fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\\n\\nGuy Kuo <guykuo@u.washington.edu>\\n\"]\n",
      "Y_train: [7 4]\n"
     ]
    }
   ],
   "source": [
    "# 加载文本分类数据集\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import random\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "print(\"sample several datas: \")\n",
    "print(\"X_train: \", X_train[0: 2])\n",
    "print(\"Y_train:\", y_train[0: 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf with 75000 features\n"
     ]
    }
   ],
   "source": [
    "#  提取文本TF-IDF数据特征\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def TFIDF(X_train, X_test, MAX_NB_WORDS=75000):\n",
    "    vectorizer_x = TfidfVectorizer(max_features=MAX_NB_WORDS)\n",
    "    X_train = vectorizer_x.fit_transform(X_train).toarray()\n",
    "    X_test = vectorizer_x.transform(X_test).toarray()\n",
    "    print(\"tf-idf with\", str(np.array(X_train).shape[1]),\"features\")\n",
    "    return X_train, X_test\n",
    "\n",
    "X_train,  X_test = TFIDF(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用PCA将文本特征降纬\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2000)\n",
    "X_train_new = pca.fit_transform(X_train)\n",
    "X_test_new = pca.transform(X_test)\n",
    "\n",
    "print(\"train with old features: \", np.array(X_train).shape)\n",
    "print(\"train with new features:\", np.array(X_train_new).shape)\n",
    "\n",
    "print(\"test with old features: \", np.array(X_test).shape)\n",
    "print(\"test with new features:\", np.array(X_test_new).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用LDA将数据降纬\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "LDA = LinearDiscriminantAnalysis(n_components=15)\n",
    "X_train_new = LDA.fit(X_train, y_train)\n",
    "X_train_new = LDA.transform(X_train)\n",
    "X_test_new = LDA.transform(X_test)\n",
    "\n",
    "print(\"train with old features: \", np.array(X_train).shape)\n",
    "print(\"train with new features:\", np.array(X_train_new).shape)\n",
    "\n",
    "print(\"test with old features: \", np.array(X_test).shape)\n",
    "print(\"test with new features:\", np.array(X_test_new).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用NMF将数据降纬\n",
    "from sklearn.decomposition import NMF\n",
    "NMF_ = NMF(n_components=2000)\n",
    "X_train_new = NMF_.fit(X_train)\n",
    "X_train_new = NMF_.transform(X_train)\n",
    "X_test_new = NMF_.transform(X_test)\n",
    "\n",
    "print(\"train with old features: \", np.array(X_train).shape)\n",
    "print(\"train with new features:\", np.array(X_train_new).shape)\n",
    "\n",
    "print(\"test with old features: \", np.array(X_test).shape)\n",
    "print(\"test with new features:\", np.array(X_test_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用random projection将数据降纬\n",
    "from sklearn import random_projection\n",
    "\n",
    "RandomProjection = random_projection.GaussianRandomProjection(n_components=2000)\n",
    "X_train_new = RandomProjection.fit_transform(X_train)\n",
    "X_test_new = RandomProjection.transform(X_test)\n",
    "\n",
    "print(\"train with old features: \", np.array(X_train).shape)\n",
    "print(\"train with new features:\", np.array(X_train_new).shape)\n",
    "\n",
    "print(\"test with old features: \", np.array(X_test).shape)\n",
    "print(\"test with new features:\", np.array(X_test_new).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "# about T-SNE\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "X = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
    "X_embedded = TSNE(n_components=2).fit_transform(X)\n",
    "print(X_embedded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.49      0.60       319\n",
      "          1       0.44      0.76      0.56       389\n",
      "          2       0.75      0.68      0.71       394\n",
      "          3       0.71      0.59      0.65       392\n",
      "          4       0.81      0.71      0.76       385\n",
      "          5       0.83      0.66      0.74       395\n",
      "          6       0.49      0.88      0.63       390\n",
      "          7       0.86      0.76      0.80       396\n",
      "          8       0.91      0.86      0.89       398\n",
      "          9       0.85      0.79      0.82       397\n",
      "         10       0.95      0.80      0.87       399\n",
      "         11       0.94      0.66      0.78       396\n",
      "         12       0.40      0.70      0.51       393\n",
      "         13       0.84      0.49      0.62       396\n",
      "         14       0.89      0.72      0.80       394\n",
      "         15       0.55      0.73      0.63       398\n",
      "         16       0.68      0.76      0.71       364\n",
      "         17       0.97      0.70      0.81       376\n",
      "         18       0.54      0.53      0.53       310\n",
      "         19       0.58      0.39      0.47       251\n",
      "\n",
      "avg / total       0.74      0.69      0.70      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rocchio classification\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', NearestCentroid()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yyhaker/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.66      0.73       319\n",
      "          1       0.68      0.70      0.69       389\n",
      "          2       0.71      0.70      0.70       394\n",
      "          3       0.65      0.71      0.68       392\n",
      "          4       0.79      0.79      0.79       385\n",
      "          5       0.83      0.64      0.72       395\n",
      "          6       0.81      0.85      0.83       390\n",
      "          7       0.86      0.74      0.79       396\n",
      "          8       0.90      0.86      0.88       398\n",
      "          9       0.91      0.85      0.88       397\n",
      "         10       0.93      0.86      0.90       399\n",
      "         11       0.91      0.81      0.86       396\n",
      "         12       0.33      0.68      0.44       393\n",
      "         13       0.86      0.71      0.78       396\n",
      "         14       0.86      0.84      0.85       394\n",
      "         15       0.85      0.88      0.87       398\n",
      "         16       0.65      0.79      0.71       364\n",
      "         17       0.96      0.75      0.84       376\n",
      "         18       0.70      0.55      0.61       310\n",
      "         19       0.62      0.55      0.59       251\n",
      "\n",
      "avg / total       0.79      0.75      0.76      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# boosting classification\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', GradientBoostingClassifier(n_estimators=100)),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.71      0.64       319\n",
      "          1       0.59      0.56      0.57       389\n",
      "          2       0.59      0.57      0.58       394\n",
      "          3       0.58      0.57      0.58       392\n",
      "          4       0.60      0.55      0.57       385\n",
      "          5       0.74      0.63      0.68       395\n",
      "          6       0.60      0.47      0.53       390\n",
      "          7       0.77      0.71      0.74       396\n",
      "          8       0.84      0.82      0.83       398\n",
      "          9       0.76      0.75      0.76       397\n",
      "         10       0.82      0.88      0.85       399\n",
      "         11       0.74      0.84      0.78       396\n",
      "         12       0.67      0.53      0.59       393\n",
      "         13       0.76      0.51      0.61       396\n",
      "         14       0.78      0.79      0.78       394\n",
      "         15       0.72      0.78      0.75       398\n",
      "         16       0.71      0.76      0.74       364\n",
      "         17       0.61      0.79      0.69       376\n",
      "         18       0.46      0.64      0.53       310\n",
      "         19       0.50      0.55      0.52       251\n",
      "\n",
      "avg / total       0.68      0.67      0.67      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# bagging classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', BaggingClassifier(KNeighborsClassifier())),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.52      0.63       319\n",
      "          1       0.81      0.65      0.72       389\n",
      "          2       0.82      0.65      0.73       394\n",
      "          3       0.67      0.78      0.72       392\n",
      "          4       0.86      0.77      0.81       385\n",
      "          5       0.89      0.75      0.82       395\n",
      "          6       0.93      0.69      0.80       390\n",
      "          7       0.85      0.92      0.88       396\n",
      "          8       0.94      0.93      0.93       398\n",
      "          9       0.92      0.90      0.91       397\n",
      "         10       0.89      0.97      0.93       399\n",
      "         11       0.59      0.97      0.74       396\n",
      "         12       0.84      0.60      0.70       393\n",
      "         13       0.92      0.74      0.82       396\n",
      "         14       0.84      0.89      0.87       394\n",
      "         15       0.44      0.98      0.61       398\n",
      "         16       0.64      0.94      0.76       364\n",
      "         17       0.93      0.91      0.92       376\n",
      "         18       0.96      0.42      0.58       310\n",
      "         19       0.97      0.14      0.24       251\n",
      "\n",
      "avg / total       0.82      0.77      0.77      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.76      0.55       319\n",
      "          1       0.50      0.61      0.55       389\n",
      "          2       0.56      0.57      0.57       394\n",
      "          3       0.53      0.58      0.56       392\n",
      "          4       0.59      0.56      0.57       385\n",
      "          5       0.69      0.60      0.64       395\n",
      "          6       0.58      0.45      0.51       390\n",
      "          7       0.75      0.69      0.72       396\n",
      "          8       0.84      0.81      0.82       398\n",
      "          9       0.77      0.72      0.74       397\n",
      "         10       0.85      0.84      0.84       399\n",
      "         11       0.76      0.84      0.80       396\n",
      "         12       0.70      0.50      0.58       393\n",
      "         13       0.82      0.49      0.62       396\n",
      "         14       0.79      0.76      0.78       394\n",
      "         15       0.75      0.76      0.76       398\n",
      "         16       0.70      0.73      0.72       364\n",
      "         17       0.62      0.76      0.69       376\n",
      "         18       0.55      0.61      0.58       310\n",
      "         19       0.56      0.49      0.52       251\n",
      "\n",
      "avg / total       0.67      0.66      0.66      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-nearest Neighbor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', KNeighborsClassifier()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.80      0.81       319\n",
      "          1       0.76      0.80      0.78       389\n",
      "          2       0.77      0.73      0.75       394\n",
      "          3       0.71      0.76      0.74       392\n",
      "          4       0.84      0.86      0.85       385\n",
      "          5       0.87      0.76      0.81       395\n",
      "          6       0.83      0.91      0.87       390\n",
      "          7       0.92      0.91      0.91       396\n",
      "          8       0.95      0.95      0.95       398\n",
      "          9       0.92      0.95      0.93       397\n",
      "         10       0.96      0.98      0.97       399\n",
      "         11       0.93      0.94      0.93       396\n",
      "         12       0.81      0.79      0.80       393\n",
      "         13       0.90      0.87      0.88       396\n",
      "         14       0.90      0.93      0.92       394\n",
      "         15       0.84      0.93      0.88       398\n",
      "         16       0.75      0.92      0.82       364\n",
      "         17       0.97      0.89      0.93       376\n",
      "         18       0.82      0.62      0.71       310\n",
      "         19       0.75      0.61      0.68       251\n",
      "\n",
      "avg / total       0.85      0.85      0.85      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine (SVM)\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.49      0.49       319\n",
      "          1       0.40      0.41      0.41       389\n",
      "          2       0.50      0.56      0.53       394\n",
      "          3       0.46      0.41      0.43       392\n",
      "          4       0.52      0.57      0.54       385\n",
      "          5       0.48      0.47      0.48       395\n",
      "          6       0.68      0.72      0.70       390\n",
      "          7       0.62      0.58      0.60       396\n",
      "          8       0.72      0.76      0.74       398\n",
      "          9       0.52      0.56      0.54       397\n",
      "         10       0.66      0.66      0.66       399\n",
      "         11       0.78      0.70      0.74       396\n",
      "         12       0.34      0.35      0.35       393\n",
      "         13       0.49      0.42      0.45       396\n",
      "         14       0.66      0.62      0.64       394\n",
      "         15       0.70      0.69      0.70       398\n",
      "         16       0.47      0.61      0.53       364\n",
      "         17       0.78      0.59      0.67       376\n",
      "         18       0.41      0.38      0.39       310\n",
      "         19       0.32      0.35      0.33       251\n",
      "\n",
      "avg / total       0.56      0.55      0.55      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', tree.DecisionTreeClassifier()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.65      0.68       319\n",
      "          1       0.56      0.69      0.62       389\n",
      "          2       0.64      0.78      0.70       394\n",
      "          3       0.63      0.64      0.64       392\n",
      "          4       0.77      0.74      0.76       385\n",
      "          5       0.76      0.66      0.71       395\n",
      "          6       0.75      0.92      0.83       390\n",
      "          7       0.80      0.80      0.80       396\n",
      "          8       0.89      0.90      0.89       398\n",
      "          9       0.78      0.91      0.84       397\n",
      "         10       0.91      0.92      0.92       399\n",
      "         11       0.88      0.92      0.90       396\n",
      "         12       0.68      0.48      0.57       393\n",
      "         13       0.84      0.66      0.74       396\n",
      "         14       0.82      0.90      0.86       394\n",
      "         15       0.68      0.93      0.78       398\n",
      "         16       0.68      0.87      0.76       364\n",
      "         17       0.95      0.82      0.88       376\n",
      "         18       0.89      0.48      0.62       310\n",
      "         19       0.77      0.30      0.43       251\n",
      "\n",
      "avg / total       0.77      0.76      0.75      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', RandomForestClassifier(n_estimators=100)),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
